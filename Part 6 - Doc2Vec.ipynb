{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596019 entries, 0 to 1596018\n",
      "Data columns (total 2 columns):\n",
      "text      1596019 non-null object\n",
      "target    1596019 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = my_df.text\n",
    "y = my_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we jump into doc2vec, it will be better to first start by word2vec. \"Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec is not a single algorithm but consists of two techniques – CBOW(Continuous bag of words) and Skip-gram model. Both of these techniques learn weights which act as word vector representations. With a corpus, CBOW model predicts the current word from a window of surrounding context words, while Skip-gram model predicts surrounding context words given the current word. In Gensim package, you can specify whether to use CBOW or Skip-gram by passing the argument \"sg\" when implementing Word2Vec. By default (sg=0), CBOW is used. Otherwise (sg=1), skip-gram is employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say we have the following sentence: \"I love dogs\". CBOW model tries to predict the word \"love\" when given \"I\", \"dogs\" as inputs, on the other hand, Skip-gram model tries to predict \"I\", \"dogs\" when given the word \"love\" as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below picture represents more formally how these two models work.\n",
    "\n",
    "![title](img/w2v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what's used as word vectors are actually not the predicted results from these models but the weights of the trained models. By extracting the weights, such a vector comes to represent in some abstract way the ‘meaning’ of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then what is doc2vec? Doc2vec uses the same logic as word2vec, but apply this to the document level. According to Mikolov et al. (2014), \"every paragraph is mapped to a unique vector, represented by a column in matrix D and every word is also mapped to a unique vector, represented by a column in matrix W. The paragraph vector and word vectors are averaged or concatenated to predict the next word in a context...The paragraph token can be thought of as another word. It acts as a memory that remembers what is missing from the current context – or the topic of the paragraph.\" https://cs.stanford.edu/~quocle/paragraph_vector.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/d2v01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DM: \n",
    "This is the Doc2Vec model analogous to CBOW model in Word2vec. The paragraph vectors are obtained by training a neural network on the task of inferring a centre word based on context words and a context paragraph. \n",
    "\n",
    "DBOW:\n",
    "This is the Doc2Vec model analogous to Skip-gram model in Word2Vec. The paragraph vectors are obtained by training a neural network on the task of predicting a probability distribution of words in a paragraph given a randomly-sampled word from the paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented Doc2Vec model using a Python library, Gensim. In case of DM model, I implemented averaging and concatenating. This is inspired by the research paper from Le and Mikolov (2014). In their paper, they have implemented DM model in two different way, using average calculation process for the paragraph matrix, and concatenating calculation method for the paragraph matrix. This has also been shown in Gensim's tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the methods I used to get the vectors for each tweet.\n",
    "\n",
    "1. DBOW (Distributed Bag of Words)\n",
    "2. DMC (Distributed Memory Concatenated)\n",
    "3. DMM (Distributed Memory Mean)\n",
    "4. DBOW + DMC\n",
    "5. DBOW + DMM\n",
    "\n",
    "With above vectors, I fit a simple logistic regression model and evaluated the result on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training Doc2Vec, I used the whole data set. The rationale behind this is that the doc2vec training is completely unsupervised and thus there is no need to hold out any data, as it is unlabelled. This rationale is inspired by the rationale of Lau and Baldwin (2016) in their research paper \"An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation\" https://arxiv.org/pdf/1607.05368.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the same rationale has been applied in the Gensim's Doc2Vec tutorial. In the IMDB tutorial, vector training is occurring on all documents of the data set, including all train/test/dev set. https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596019"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_x_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1103371.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the developer Radim Řehůřek who created Gensim,\n",
    "\"One caveat of the way this algorithm runs is that, since the learning rate decrease over the course of iterating over the data, labels which are only seen in a single LabeledSentence during training will only be trained with a fixed learning rate. This frequently produces less than optimal results.\"\n",
    "\n",
    "Below iteration implement explicit multiple-pass, alpha-reduction approach with added shuffling. This has been already presented in Gensim's IMDB tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1219082.43it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1261002.16it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1288925.92it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1305433.30it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1272539.49it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1326664.83it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1303369.44it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1311243.19it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1374487.58it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1344628.55it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1342260.54it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1312454.04it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1316521.68it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1298431.37it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1310747.92it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1286284.31it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1297549.99it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1256376.51it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1265628.99it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1333229.94it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1353057.05it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1282427.14it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1319579.05it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1299535.15it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1247262.98it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1308923.63it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1276290.36it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1273963.48it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1315995.00it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1236473.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 59s, sys: 17min 26s, total: 55min 25s\n",
      "Wall time: 34min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.002\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dbow = get_vectors(model_ug_dbow, x_train, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73890977443609018"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the DBOW model doesn't learn the meaning of the individual words, but as features to feed to a classifier, it seems like it's doing its job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the result doesn't seem to excel count vectorizer or Tfidf vectorizer. It might not be a direct comparison since either count vectorizer of Tfidf vectorizer uses a large number of features to represent a tweet, but in this case, a vector for each tweet has only 200 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_dbow.save('d2v_model_ug_dbow.doc2vec')\n",
    "model_ug_dbow = Doc2Vec.load('d2v_model_ug_dbow.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Momory (concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 953468.23it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmc.build_vocab([x for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1306549.28it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1419834.51it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1287296.73it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1090579.91it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1395998.90it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1403537.78it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1344315.05it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1393606.22it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1345848.57it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1368462.81it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1289542.44it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1407111.38it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1384729.94it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1358161.42it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1376371.99it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1252529.01it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1327374.31it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1371211.53it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1336089.44it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1348504.94it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1118630.26it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1370814.77it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1370088.68it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1351904.20it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1257098.94it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1304723.69it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1367848.19it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1268932.54it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1340283.67it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1242295.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47min 4s, sys: 16min 55s, total: 1h 3min 59s\n",
      "Wall time: 35min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmc.alpha -= 0.002\n",
    "    model_ug_dmc.min_alpha = model_ug_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_dmc = Doc2Vec.load('d2v_model_ug_dmc.doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's nice about Doc2Vec is that after training you can retrieve not only document vectors but also individual word vectors as well. Note, however, that a Doc2Vec DBOW model doesn't learn semantic word vectors, so the word vectors you retrieve from pure DBOW model will be the automatic randomly-initialized vectors, with no meaning.\n",
    "But with DM model, you can see the semantic relationship between words. Let's see what word vectors it has learned through training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goood', 0.7454031705856323),\n",
       " ('gud', 0.7452770471572876),\n",
       " ('gd', 0.7434319853782654),\n",
       " ('gooood', 0.7358574271202087),\n",
       " ('great', 0.7102019786834717),\n",
       " ('goooood', 0.6563930511474609),\n",
       " ('guud', 0.6441871523857117),\n",
       " ('gooooood', 0.6416404843330383),\n",
       " ('gooooooood', 0.6410443782806396),\n",
       " ('cnceled', 0.6380959153175354)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hapy', 0.7785520553588867),\n",
       " ('hapi', 0.7260264158248901),\n",
       " ('happpy', 0.7140897512435913),\n",
       " ('happpppy', 0.6873939037322998),\n",
       " ('pleased', 0.6722116470336914),\n",
       " ('hppy', 0.6686583161354065),\n",
       " ('happpppppy', 0.6357202529907227),\n",
       " ('teuni', 0.6338286399841309),\n",
       " ('haaappy', 0.6285831928253174),\n",
       " ('unhappy', 0.6153473854064941)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's interesting with DMC model is, somehow it learned all the misspelled version of a word as you can see from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('myspace', 0.8975507020950317),\n",
       " ('fb', 0.8213573694229126),\n",
       " ('youtube', 0.7994770407676697),\n",
       " ('msn', 0.7978468537330627),\n",
       " ('ym', 0.7916175127029419),\n",
       " ('bebo', 0.7702169418334961),\n",
       " ('weebly', 0.764090359210968),\n",
       " ('yahoo', 0.7522760033607483),\n",
       " ('flickr', 0.7478793263435364),\n",
       " ('gmail', 0.7433972954750061)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smaller', 0.6462364792823792),\n",
       " ('larger', 0.6360152959823608),\n",
       " ('confections', 0.5971038341522217),\n",
       " ('stricter', 0.5868656039237976),\n",
       " ('braver', 0.5825048685073853),\n",
       " ('chillier', 0.5745378732681274),\n",
       " ('sharper', 0.5676980018615723),\n",
       " ('colorfull', 0.567488431930542),\n",
       " ('scarier', 0.5673887729644775),\n",
       " ('slower', 0.5586768388748169)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar(positive=['bigger', 'small'], negative=['big'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model successfully catches the comparative form of \"small\", on feeding the word \"big\" and \"bigger\". The above line of code is like asking the model to add the vectors associated with the word \"bigger\" and \"small\" while subtracting \"big\" is equal to the top result, \"smaller\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dmc = get_vectors(model_ug_dmc, x_train, 100)\n",
    "validation_vecs_dmc = get_vectors(model_ug_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6646616541353384"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_dmc.save('d2v_model_ug_dmc.doc2vec')\n",
    "model_ug_dmc = Doc2Vec.load('d2v_model_ug_dmc.doc2vec')\n",
    "model_ug_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Memory (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1236915.22it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmm.build_vocab([x for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1098305.56it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1300438.43it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1344649.08it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1342917.83it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1381563.17it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1263600.00it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1390100.80it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1354605.11it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1332752.43it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1299577.54it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1303878.45it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1347850.31it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1285677.08it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1314748.43it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1504333.07it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1492316.56it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1571766.68it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1545204.82it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1530997.57it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1528397.94it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1508346.34it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1487509.60it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1525696.54it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1527180.00it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1553011.40it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1214527.49it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1202016.99it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1290375.40it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1265959.28it/s]\n",
      "100%|██████████| 1596019/1596019 [00:01<00:00, 1244457.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 41s, sys: 22min 21s, total: 1h 13min 3s\n",
      "Wall time: 44min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmm.alpha -= 0.002\n",
    "    model_ug_dmm.min_alpha = model_ug_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.9227250814437866),\n",
       " ('bad', 0.883027195930481),\n",
       " ('nice', 0.8792778849601746),\n",
       " ('this', 0.8624216914176941),\n",
       " ('you', 0.8607751727104187),\n",
       " ('busy', 0.8561026453971863),\n",
       " ('sad', 0.8500779867172241),\n",
       " ('better', 0.8498481512069702),\n",
       " ('long', 0.8439643979072571),\n",
       " ('not', 0.8438945412635803)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmm.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hapy', 0.7785520553588867),\n",
       " ('hapi', 0.7260264158248901),\n",
       " ('happpy', 0.7140897512435913),\n",
       " ('happpppy', 0.6873939037322998),\n",
       " ('pleased', 0.6722116470336914),\n",
       " ('hppy', 0.6686583161354065),\n",
       " ('happpppppy', 0.6357202529907227),\n",
       " ('teuni', 0.6338286399841309),\n",
       " ('haaappy', 0.6285831928253174),\n",
       " ('unhappy', 0.6153473854064941)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dmm = get_vectors(model_ug_dmm, x_train, 100)\n",
    "validation_vecs_dmm = get_vectors(model_ug_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72556390977443608"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_dmm.save('d2v_model_ug_dmm.doc2vec')\n",
    "model_ug_dmm = Doc2Vec.load('d2v_model_ug_dmm.doc2vec')\n",
    "model_ug_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since I have the document vectors from four different models, now I can concatenate them in combination to see how it affects the performance. Below I defined a simple function to concatenate document vectors from different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, x_train, 200)\n",
    "validation_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 22s, sys: 14min 10s, total: 16min 32s\n",
      "Wall time: 36min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74580200501253135"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmc, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 7min 46s, total: 9min 34s\n",
      "Wall time: 20min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75513784461152877"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmm, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of unigram, concatenating document vectors in different combination boosted the model performance. The best validation accuracy I got from a single model is from DBOW at 73.89%. With concatenated vectors, I get the highest validation accuracy of 75.51% with DBOW+DMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
